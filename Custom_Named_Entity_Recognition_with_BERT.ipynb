{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ab11bc259d1d4e7f889892793cef5bf1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_706e2b0ff4cc40829b12412323287620","IPY_MODEL_367cc6dcb6be49fb9e08f7c543321459","IPY_MODEL_13a555929993415db4190649250e52e9"],"layout":"IPY_MODEL_cf62c65da4bb4e16b2e64be5ec043aaf"}},"706e2b0ff4cc40829b12412323287620":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b810e5afa854ccba7c3193517886d7e","placeholder":"​","style":"IPY_MODEL_39b8dba60b3d4e49a27b8f05b8d160f4","value":"tokenizer_config.json: 100%"}},"367cc6dcb6be49fb9e08f7c543321459":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2ad9c5cb6884598bd4bb5ae12c108fa","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5da7e5d1a6d4eb39bb8d44e69d73c5b","value":48}},"13a555929993415db4190649250e52e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c96b69aaabc14f95badc4f299358b056","placeholder":"​","style":"IPY_MODEL_fe98333e23364d60a211e81de70bfb6d","value":" 48.0/48.0 [00:00&lt;00:00, 1.32kB/s]"}},"cf62c65da4bb4e16b2e64be5ec043aaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b810e5afa854ccba7c3193517886d7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39b8dba60b3d4e49a27b8f05b8d160f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2ad9c5cb6884598bd4bb5ae12c108fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5da7e5d1a6d4eb39bb8d44e69d73c5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c96b69aaabc14f95badc4f299358b056":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe98333e23364d60a211e81de70bfb6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e4da337fc644d869c7530c97ec2bbdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1fea6b0e3104c06afee638b4c3096ea","IPY_MODEL_72dd26a8b2894c3e87e1dec910e39890","IPY_MODEL_dbaf6baf137a4ea1a7729b05be2d338d"],"layout":"IPY_MODEL_65b9313cd6d74ef4bbf3155f86b90d90"}},"e1fea6b0e3104c06afee638b4c3096ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcd89d1d821944a8a15de40b0cf6fc11","placeholder":"​","style":"IPY_MODEL_fa30d1bae9cb46d68bd0c5b67e7170e8","value":"vocab.txt: 100%"}},"72dd26a8b2894c3e87e1dec910e39890":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3b410e7ad2d4e2b95ff45865b95abd5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26c4eef3932e40239209d8435906af12","value":231508}},"dbaf6baf137a4ea1a7729b05be2d338d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02606ef6bdb043c19dadc9ac4fc55e4d","placeholder":"​","style":"IPY_MODEL_df8ed90e9d52414ea6d63c3fd5c8b13d","value":" 232k/232k [00:00&lt;00:00, 2.25MB/s]"}},"65b9313cd6d74ef4bbf3155f86b90d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcd89d1d821944a8a15de40b0cf6fc11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa30d1bae9cb46d68bd0c5b67e7170e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3b410e7ad2d4e2b95ff45865b95abd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26c4eef3932e40239209d8435906af12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02606ef6bdb043c19dadc9ac4fc55e4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df8ed90e9d52414ea6d63c3fd5c8b13d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"366bb67cf538431eb7132e4277d724bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99c157880cc449989ae393d641b40e40","IPY_MODEL_5401e3345ce740018624ff95540a8616","IPY_MODEL_4d49e36a3e8e4763a100ede5260779a2"],"layout":"IPY_MODEL_ca15c1226a5345b2aa91734a767fe5db"}},"99c157880cc449989ae393d641b40e40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b502de2f011f4d6f80d941dceb29b0f6","placeholder":"​","style":"IPY_MODEL_c28a0022bd36413ebde529aaf55b8132","value":"tokenizer.json: 100%"}},"5401e3345ce740018624ff95540a8616":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5808d7e4254c40879cfc8373d7671f36","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e36b30ec97d40a390d8a6b2200a0687","value":466062}},"4d49e36a3e8e4763a100ede5260779a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f823deca7a646e9b86ea22845e34f90","placeholder":"​","style":"IPY_MODEL_c2f9b435bebd412fb8d6e8f8bf6d7d26","value":" 466k/466k [00:00&lt;00:00, 8.20MB/s]"}},"ca15c1226a5345b2aa91734a767fe5db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b502de2f011f4d6f80d941dceb29b0f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c28a0022bd36413ebde529aaf55b8132":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5808d7e4254c40879cfc8373d7671f36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e36b30ec97d40a390d8a6b2200a0687":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f823deca7a646e9b86ea22845e34f90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f9b435bebd412fb8d6e8f8bf6d7d26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34cb6f847f4c4ae7ad00d263d47c5f6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d239625bf38459fa46083319721cb72","IPY_MODEL_31b37513852a4a3094119a167cdd8a3f","IPY_MODEL_cd9568822c19492fbce6d71fb03035a6"],"layout":"IPY_MODEL_651119636ea24dfc8ac5b3cae5afc884"}},"2d239625bf38459fa46083319721cb72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19ece6e2def14d25a4949ec04897679c","placeholder":"​","style":"IPY_MODEL_25e41bfa3895420286b06bc48cd48755","value":"config.json: 100%"}},"31b37513852a4a3094119a167cdd8a3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17c95724129a407cbb7d71addde92c68","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cdcb461014874565aaba0ba24575647e","value":570}},"cd9568822c19492fbce6d71fb03035a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_308584f79a454ca0aa6438674d998105","placeholder":"​","style":"IPY_MODEL_8573c183e7c948809f3d29c8c69a89a1","value":" 570/570 [00:00&lt;00:00, 13.9kB/s]"}},"651119636ea24dfc8ac5b3cae5afc884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19ece6e2def14d25a4949ec04897679c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25e41bfa3895420286b06bc48cd48755":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17c95724129a407cbb7d71addde92c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdcb461014874565aaba0ba24575647e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"308584f79a454ca0aa6438674d998105":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8573c183e7c948809f3d29c8c69a89a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"491c376d88e443f5ae64f8dd17444242":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_469c61c781ab469383b446bacc9ac35d","IPY_MODEL_c5ef40d523044ebda92b72f671f227b2","IPY_MODEL_f7bec5cb1c28448e99b822c3c639b022"],"layout":"IPY_MODEL_45901b63fbfe47239b403541d166a097"}},"469c61c781ab469383b446bacc9ac35d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0008ee1275df41b8b4537de220482e6a","placeholder":"​","style":"IPY_MODEL_3a44ea90c28c45d69945de4b85053af5","value":"model.safetensors: 100%"}},"c5ef40d523044ebda92b72f671f227b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d8cfda319e84010b30e4a1752d716e1","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbde2bbb44ff4b0495b341521091900d","value":440449768}},"f7bec5cb1c28448e99b822c3c639b022":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4711ad35dda8446aa8560ee053a04e77","placeholder":"​","style":"IPY_MODEL_cb66d19064dc4f6296005b387ffad960","value":" 440M/440M [00:04&lt;00:00, 103MB/s]"}},"45901b63fbfe47239b403541d166a097":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0008ee1275df41b8b4537de220482e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a44ea90c28c45d69945de4b85053af5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d8cfda319e84010b30e4a1752d716e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbde2bbb44ff4b0495b341521091900d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4711ad35dda8446aa8560ee053a04e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb66d19064dc4f6296005b387ffad960":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"e7wfLWyYkvDi"},"source":["#### **Importing Python Libraries and preparing the environment**\n","\n","This notebook assumes that you have the following libraries installed:\n","* pandas\n","* numpy\n","* sklearn\n","* pytorch\n","* transformers\n","* seqeval\n","\n","As we are running this in Google Colab, the only libraries we need to additionally install are transformers and seqeval (GPU version):"]},{"cell_type":"code","metadata":{"id":"d4_YJqjR_Gjw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f5e65f7-fa73-407c-8ed5-b957ff4761e7","executionInfo":{"status":"ok","timestamp":1710747331028,"user_tz":-330,"elapsed":10091,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["!pip install transformers seqeval[gpu]"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Collecting seqeval[gpu]\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m943.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.2.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=ef8adb256cc5c9174944c14e9d367c79b0a7d9a454b169e21e1ed9ff58973150\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}]},{"cell_type":"code","metadata":{"id":"IEnlUbgm8z3B","executionInfo":{"status":"ok","timestamp":1710747337613,"user_tz":-330,"elapsed":6594,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertConfig, BertForTokenClassification"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"7tZg6KTykfVx","executionInfo":{"status":"ok","timestamp":1710747337613,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jzq1w3L1K5M-"},"source":["As deep learning can be accellerated a lot using a GPU instead of a CPU, make sure you can run this notebook in a GPU runtime (which Google Colab provides for free! - check \"Runtime\" - \"Change runtime type\" - and set the hardware accelerator to \"GPU\").\n","\n","We can set the default device to GPU using the following code (if it prints \"cuda\", it means the GPU has been recognized):"]},{"cell_type":"code","metadata":{"id":"Sm1krxJtKxpx","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e7aa8c9-bf31-43e8-dc0d-7973d5b728a2","executionInfo":{"status":"ok","timestamp":1710747337614,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","metadata":{"id":"ahwMsmyG5ZPE"},"source":["#### **preprocessing the data**"]},{"cell_type":"code","metadata":{"id":"deLB9HVX5I6F","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"73dfebe8-9606-47c4-a881-1a86595a609f","executionInfo":{"status":"ok","timestamp":1710747339358,"user_tz":-330,"elapsed":1753,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["data = pd.read_csv(\"/content/drive/MyDrive/NER_Classification/data/ner_dataset.csv\", encoding='unicode_escape')\n","data.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"],"text/html":["\n","  <div id=\"df-bf9be395-9a9a-43d3-9675-648dd06a772f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf9be395-9a9a-43d3-9675-648dd06a772f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bf9be395-9a9a-43d3-9675-648dd06a772f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bf9be395-9a9a-43d3-9675-648dd06a772f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b84f11f6-c86d-4afe-a61d-cbb6e38f5cec\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b84f11f6-c86d-4afe-a61d-cbb6e38f5cec')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b84f11f6-c86d-4afe-a61d-cbb6e38f5cec button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"ucYjhq6uRAmY"},"source":["Let's check how many sentences and words (and corresponding tags) there are in this dataset:"]},{"cell_type":"code","metadata":{"id":"6gMibEJXTKDw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"653f15ff-de09-4edd-caa6-4fedf87d350d","executionInfo":{"status":"ok","timestamp":1710747340028,"user_tz":-330,"elapsed":703,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["data.count()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentence #      47959\n","Word          1048575\n","POS           1048575\n","Tag           1048575\n","dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"sUGXZOfE_GkO"},"source":["As we can see, there are approximately 48,000 sentences in the dataset, comprising more than 1 million words and tags (quite huge!). This corresponds to approximately 20 words per sentence.\n","\n","Let's have a look at the different NER tags, and their frequency:"]},{"cell_type":"code","metadata":{"tags":[],"id":"s4Jn1fVT_GkO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"08f796d6-9a59-4b77-a8a2-9e22e7e98317","executionInfo":{"status":"ok","timestamp":1710747340463,"user_tz":-330,"elapsed":446,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n","frequencies = data.Tag.value_counts()\n","frequencies"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of tags: 17\n"]},{"output_type":"execute_result","data":{"text/plain":["O        887908\n","B-geo     37644\n","B-tim     20333\n","B-org     20143\n","I-per     17251\n","B-per     16990\n","I-org     16784\n","B-gpe     15870\n","I-geo      7414\n","I-tim      6528\n","B-art       402\n","B-eve       308\n","I-art       297\n","I-eve       253\n","B-nat       201\n","I-gpe       198\n","I-nat        51\n","Name: Tag, dtype: int64"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"gsX0ebih_GkS"},"source":["There are 8 category tags, each with a \"beginning\" and \"inside\" variant, and the \"outside\" tag. It is not really clear what these tags mean - \"geo\" probably stands for geographical entity, \"gpe\" for geopolitical entity, and so on. They do not seem to correspond with what the publisher says on Kaggle. Some tags seem to be underrepresented. Let's print them by frequency (highest to lowest):"]},{"cell_type":"code","metadata":{"tags":[],"id":"CmjbHirJ_GkS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd4d70be-d9ac-43b2-a957-a83ae7990c80","executionInfo":{"status":"ok","timestamp":1710747340464,"user_tz":-330,"elapsed":19,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["tags = {}\n","for tag, count in zip(frequencies.index, frequencies):\n","    if tag != \"O\":\n","        if tag[2:5] not in tags.keys():\n","            tags[tag[2:5]] = count\n","        else:\n","            tags[tag[2:5]] += count\n","    continue\n","\n","print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[('geo', 45058), ('org', 36927), ('per', 34241), ('tim', 26861), ('gpe', 16068), ('art', 699), ('eve', 561), ('nat', 252)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"aGUQemBz_GkV"},"source":["Let's remove \"art\", \"eve\" and \"nat\" named entities, as performance on them will probably be not comparable to the other named entities."]},{"cell_type":"code","metadata":{"id":"8iorLrU4_GkW","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"6f62ebad-cb5e-4f5c-e281-54be7d55469e","executionInfo":{"status":"ok","timestamp":1710747340466,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n","data = data[~data.Tag.isin(entities_to_remove)]\n","data.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1          NaN             of   IN   O\n","2          NaN  demonstrators  NNS   O\n","3          NaN           have  VBP   O\n","4          NaN        marched  VBN   O"],"text/html":["\n","  <div id=\"df-1276b115-aadf-48ae-8b72-0b51b699e422\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1276b115-aadf-48ae-8b72-0b51b699e422')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1276b115-aadf-48ae-8b72-0b51b699e422 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1276b115-aadf-48ae-8b72-0b51b699e422');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b7b0794c-0f4d-44d8-9168-130732e58abf\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7b0794c-0f4d-44d8-9168-130732e58abf')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b7b0794c-0f4d-44d8-9168-130732e58abf button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"mskU4h0oRKEF"},"source":["Now, we have to ask ourself the question: what is a training example in the case of NER, which is provided in a single forward pass? A training example is typically a **sentence**, with corresponding IOB tags. Let's group the words and corresponding tags by sentence:"]},{"cell_type":"code","metadata":{"id":"zkW2vNcO-uMH","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"390131ff-3b7d-4f68-82a5-38b79a6a1386","executionInfo":{"status":"ok","timestamp":1710747341080,"user_tz":-330,"elapsed":623,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n","data = data.fillna(method='ffill')\n","data.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Sentence #           Word  POS Tag\n","0  Sentence: 1      Thousands  NNS   O\n","1  Sentence: 1             of   IN   O\n","2  Sentence: 1  demonstrators  NNS   O\n","3  Sentence: 1           have  VBP   O\n","4  Sentence: 1        marched  VBN   O"],"text/html":["\n","  <div id=\"df-8181d8f8-4c1c-402d-a54f-2a3423e97396\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 1</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 1</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 1</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8181d8f8-4c1c-402d-a54f-2a3423e97396')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8181d8f8-4c1c-402d-a54f-2a3423e97396 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8181d8f8-4c1c-402d-a54f-2a3423e97396');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-eeae5d97-7b34-41be-bd01-d16308c59a74\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eeae5d97-7b34-41be-bd01-d16308c59a74')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-eeae5d97-7b34-41be-bd01-d16308c59a74 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Hmd-ow389k6Y","colab":{"base_uri":"https://localhost:8080/","height":310},"outputId":"39f4a29a-b7a0-4380-ac4c-26cf0dedc37a","executionInfo":{"status":"ok","timestamp":1710747356509,"user_tz":-330,"elapsed":15448,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["# let's create a new column called \"sentence\" which groups the words by sentence\n","data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n","# let's also create a new column called \"word_labels\" which groups the tags by sentence\n","data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n","data.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Sentence #           Word  POS Tag  \\\n","0  Sentence: 1      Thousands  NNS   O   \n","1  Sentence: 1             of   IN   O   \n","2  Sentence: 1  demonstrators  NNS   O   \n","3  Sentence: 1           have  VBP   O   \n","4  Sentence: 1        marched  VBN   O   \n","\n","                                            sentence  \\\n","0  Thousands of demonstrators have marched throug...   \n","1  Thousands of demonstrators have marched throug...   \n","2  Thousands of demonstrators have marched throug...   \n","3  Thousands of demonstrators have marched throug...   \n","4  Thousands of demonstrators have marched throug...   \n","\n","                                         word_labels  \n","0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n","1  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n","2  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n","3  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n","4  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  "],"text/html":["\n","  <div id=\"df-9fae2dd0-2406-43a2-921f-2ea634a36ba5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>POS</th>\n","      <th>Tag</th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>Thousands</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 1</td>\n","      <td>of</td>\n","      <td>IN</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 1</td>\n","      <td>demonstrators</td>\n","      <td>NNS</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1</td>\n","      <td>have</td>\n","      <td>VBP</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 1</td>\n","      <td>marched</td>\n","      <td>VBN</td>\n","      <td>O</td>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fae2dd0-2406-43a2-921f-2ea634a36ba5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9fae2dd0-2406-43a2-921f-2ea634a36ba5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9fae2dd0-2406-43a2-921f-2ea634a36ba5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1faefd96-ae7b-4450-9f19-b5fe20ac14dd\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1faefd96-ae7b-4450-9f19-b5fe20ac14dd')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1faefd96-ae7b-4450-9f19-b5fe20ac14dd button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"JsjhdQbE-Lve"},"source":["Let's have a look at the different NER tags.\n","\n","We create 2 dictionaries: one that maps individual tags to indices, and one that maps indices to their individual tags. This is necessary in order to create the labels (as computers work with numbers = indices, rather than words = tags) - see further in this notebook."]},{"cell_type":"code","metadata":{"id":"CFRDM8WsQXvL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"211fa37e-cac1-41ce-b99d-0e0ad0c0b8ea","executionInfo":{"status":"ok","timestamp":1710747357210,"user_tz":-330,"elapsed":735,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["label2id = {k: v for v, k in enumerate(data.Tag.unique())}\n","id2label = {v: k for v, k in enumerate(data.Tag.unique())}\n","label2id"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'O': 0,\n"," 'B-geo': 1,\n"," 'B-gpe': 2,\n"," 'B-per': 3,\n"," 'I-geo': 4,\n"," 'B-org': 5,\n"," 'I-org': 6,\n"," 'B-tim': 7,\n"," 'I-per': 8,\n"," 'I-gpe': 9,\n"," 'I-tim': 10}"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"J08Cvk_USgbM"},"source":["As we can see, there are now only 10 different tags.\n","\n","Let's only keep the \"sentence\" and \"word_labels\" columns, and drop duplicates:"]},{"cell_type":"code","metadata":{"id":"SrEgd4PZUgmF","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"b5199254-1d73-4a8c-fa9d-c969b42c9b3c","executionInfo":{"status":"ok","timestamp":1710747358396,"user_tz":-330,"elapsed":1191,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n","data.head()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            sentence  \\\n","0  Thousands of demonstrators have marched throug...   \n","1  Families of soldiers killed in the conflict jo...   \n","2  They marched from the Houses of Parliament to ...   \n","3  Police put the number of marchers at 10,000 wh...   \n","4  The protest comes on the eve of the annual con...   \n","\n","                                         word_labels  \n","0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n","1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...  \n","2                O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O  \n","3                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n","4  O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...  "],"text/html":["\n","  <div id=\"df-dc823301-6413-4bc9-b0c8-e686d1d67f57\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Thousands of demonstrators have marched throug...</td>\n","      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Families of soldiers killed in the conflict jo...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>They marched from the Houses of Parliament to ...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Police put the number of marchers at 10,000 wh...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The protest comes on the eve of the annual con...</td>\n","      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc823301-6413-4bc9-b0c8-e686d1d67f57')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dc823301-6413-4bc9-b0c8-e686d1d67f57 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dc823301-6413-4bc9-b0c8-e686d1d67f57');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2cd77a26-4b1d-4138-94d6-9b4aa744a4c3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cd77a26-4b1d-4138-94d6-9b4aa744a4c3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2cd77a26-4b1d-4138-94d6-9b4aa744a4c3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 47571,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47541,\n        \"samples\": [\n          \"Tuesday , Britain , the United States , China , Russia and France said the IAEA should refer Iran to the United Nations Security Council for allegedly violating a key nuclear treaty with its atomic program .\",\n          \"The 2008 municipal elections were marred by widespread irregularities .\",\n          \"Israeli warplanes have dropped leaflets warning Gaza residents to stay clear of the border , after Palestinian militants fired at least 10 mortar shells at Israel .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33040,\n        \"samples\": [\n          \"O,B-geo,O,O,O,O,O,B-geo,B-tim,O,O,O,O,O,O,O\",\n          \"O,O,O,B-gpe,O,B-tim,O,O,O,O,O,O,B-org,O,O,O,O\",\n          \"O,B-geo,I-geo,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O,B-geo,I-geo,O,O,O,O,O,O,B-org,I-org,O,O,O,O,O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"r3ArUiVRqw0C","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4a6933f-139a-4506-b3ba-b872de3f83dc","executionInfo":{"status":"ok","timestamp":1710747358396,"user_tz":-330,"elapsed":39,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["len(data)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["47571"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"U8obZumRTBrT"},"source":["Let's verify that a random sentence and its corresponding tags are correct:"]},{"cell_type":"code","metadata":{"id":"eUvupomW_fbe","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"3af7ead2-ef67-46ed-fa7b-ad8ba9968e1f","executionInfo":{"status":"ok","timestamp":1710747358396,"user_tz":-330,"elapsed":30,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["data.iloc[41].sentence"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Bedfordshire police said Tuesday that Omar Khayam was arrested in Bedford for breaching the conditions of his parole .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"0dLyY3Oi_lvp","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"7ddee67a-f5f2-4556-9c55-2d286f09c5da","executionInfo":{"status":"ok","timestamp":1710747358397,"user_tz":-330,"elapsed":29,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["data.iloc[41].word_labels"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'B-gpe,O,O,B-tim,O,B-per,I-per,O,O,O,B-geo,O,O,O,O,O,O,O,O'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"f5EHpuB78pIa"},"source":["#### **Preparing the dataset and dataloader**"]},{"cell_type":"markdown","metadata":{"id":"15x7zmZnTgFx"},"source":["Now that our data is preprocessed, we can turn it into PyTorch tensors such that we can provide it to the model. Let's start by defining some key variables that will be used later on in the training/evaluation process:"]},{"cell_type":"code","metadata":{"id":"lgNSM8Xz79Mg","tags":[],"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["ab11bc259d1d4e7f889892793cef5bf1","706e2b0ff4cc40829b12412323287620","367cc6dcb6be49fb9e08f7c543321459","13a555929993415db4190649250e52e9","cf62c65da4bb4e16b2e64be5ec043aaf","6b810e5afa854ccba7c3193517886d7e","39b8dba60b3d4e49a27b8f05b8d160f4","e2ad9c5cb6884598bd4bb5ae12c108fa","e5da7e5d1a6d4eb39bb8d44e69d73c5b","c96b69aaabc14f95badc4f299358b056","fe98333e23364d60a211e81de70bfb6d","4e4da337fc644d869c7530c97ec2bbdf","e1fea6b0e3104c06afee638b4c3096ea","72dd26a8b2894c3e87e1dec910e39890","dbaf6baf137a4ea1a7729b05be2d338d","65b9313cd6d74ef4bbf3155f86b90d90","bcd89d1d821944a8a15de40b0cf6fc11","fa30d1bae9cb46d68bd0c5b67e7170e8","b3b410e7ad2d4e2b95ff45865b95abd5","26c4eef3932e40239209d8435906af12","02606ef6bdb043c19dadc9ac4fc55e4d","df8ed90e9d52414ea6d63c3fd5c8b13d","366bb67cf538431eb7132e4277d724bd","99c157880cc449989ae393d641b40e40","5401e3345ce740018624ff95540a8616","4d49e36a3e8e4763a100ede5260779a2","ca15c1226a5345b2aa91734a767fe5db","b502de2f011f4d6f80d941dceb29b0f6","c28a0022bd36413ebde529aaf55b8132","5808d7e4254c40879cfc8373d7671f36","4e36b30ec97d40a390d8a6b2200a0687","7f823deca7a646e9b86ea22845e34f90","c2f9b435bebd412fb8d6e8f8bf6d7d26","34cb6f847f4c4ae7ad00d263d47c5f6a","2d239625bf38459fa46083319721cb72","31b37513852a4a3094119a167cdd8a3f","cd9568822c19492fbce6d71fb03035a6","651119636ea24dfc8ac5b3cae5afc884","19ece6e2def14d25a4949ec04897679c","25e41bfa3895420286b06bc48cd48755","17c95724129a407cbb7d71addde92c68","cdcb461014874565aaba0ba24575647e","308584f79a454ca0aa6438674d998105","8573c183e7c948809f3d29c8c69a89a1"]},"executionInfo":{"status":"ok","timestamp":1710747361936,"user_tz":-330,"elapsed":3566,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}},"outputId":"731f3e13-0e85-4364-f252-16010fd364f3"},"source":["MAX_LEN = 128\n","TRAIN_BATCH_SIZE = 4\n","VALID_BATCH_SIZE = 2\n","EPOCHS = 1\n","LEARNING_RATE = 1e-05\n","MAX_GRAD_NORM = 10\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab11bc259d1d4e7f889892793cef5bf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e4da337fc644d869c7530c97ec2bbdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"366bb67cf538431eb7132e4277d724bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34cb6f847f4c4ae7ad00d263d47c5f6a"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"wPYV2Ld6Tr5I"},"source":["A tricky part of NER with BERT is that BERT relies on **wordpiece tokenization**, rather than word tokenization. This means that we should also define the labels at the wordpiece-level, rather than the word-level!\n","\n","For example, if you have word like \"Washington\" which is labeled as \"b-gpe\", but it gets tokenized to \"Wash\", \"##ing\", \"##ton\", then we will have to propagate the word’s original label to all of its wordpieces: \"b-gpe\", \"b-gpe\", \"b-gpe\". The model should be able to produce the correct labels for each individual wordpiece. The function below (taken from [here](https://github.com/chambliss/Multilingual_NER/blob/master/python/utils/main_utils.py#L118)) implements this.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"RNzSgZTfGUd8","executionInfo":{"status":"ok","timestamp":1710747361937,"user_tz":-330,"elapsed":34,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n","    \"\"\"\n","    Word piece tokenization makes it difficult to match word labels\n","    back up with individual word pieces. This function tokenizes each\n","    word one at a time so that it is easier to preserve the correct\n","    label for each subword. It is, of course, a bit slower in processing\n","    time, but it will help our model achieve higher accuracy.\n","    \"\"\"\n","\n","    tokenized_sentence = []\n","    labels = []\n","\n","    sentence = sentence.strip()\n","\n","    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n","\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = tokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        labels.extend([label] * n_subwords)\n","\n","    return tokenized_sentence, labels"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ez7qlFHl56ZW"},"source":["Note that this is a **design decision**. You could also decide to only label the first wordpiece of each word and let the model only learn this (this is what was done in the original BERT paper, see Github discussion [here](https://github.com/huggingface/transformers/issues/64#issuecomment-443703063)). Another design decision could be to give the first wordpiece of each word the original word label, and then use the label “X” for all subsequent subwords of that word.\n","\n","All of them lead to good performance.\n","\n","Next, we define a regular PyTorch [dataset class](https://pytorch.org/docs/stable/data.html) (which transforms examples of a dataframe to PyTorch tensors). Here, each sentence gets tokenized, the special tokens that BERT expects are added, the tokens are padded or truncated based on the max length of the model, the attention mask is created and the labels are created based on the dictionary which we defined above.\n","\n","For more information about BERT's inputs, see [here](https://huggingface.co/transformers/glossary.html).  "]},{"cell_type":"code","metadata":{"id":"aJty_Abw8_xK","executionInfo":{"status":"ok","timestamp":1710747361937,"user_tz":-330,"elapsed":30,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["class dataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __getitem__(self, index):\n","        # step 1: tokenize (and adapt corresponding labels)\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index]\n","        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n","\n","        # step 2: add special tokens (and corresponding labels)\n","        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n","        labels.insert(0, \"O\") # add outside label for [CLS] token\n","        labels.insert(-1, \"O\") # add outside label for [SEP] token\n","\n","        # step 3: truncating/padding\n","        maxlen = self.max_len\n","\n","        if (len(tokenized_sentence) > maxlen):\n","          # truncate\n","          tokenized_sentence = tokenized_sentence[:maxlen]\n","          labels = labels[:maxlen]\n","        else:\n","          # pad\n","          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n","          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n","\n","        # step 4: obtain the attention mask\n","        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n","\n","        # step 5: convert tokens to input ids\n","        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n","\n","        label_ids = [label2id[label] for label in labels]\n","        # the following line is deprecated\n","        #label_ids = [label if label != 0 else -100 for label in label_ids]\n","\n","        return {\n","              'ids': torch.tensor(ids, dtype=torch.long),\n","              'mask': torch.tensor(attn_mask, dtype=torch.long),\n","              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n","              'targets': torch.tensor(label_ids, dtype=torch.long)\n","        }\n","\n","    def __len__(self):\n","        return self.len"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hTP7zuWGWGUd"},"source":["Now, based on the class we defined above, we can create 2 datasets, one for training and one for testing. Let's use a 80/20 split:"]},{"cell_type":"code","metadata":{"id":"jrkdZBLYHVcB","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"26f09810-d918-4b0c-9947-827aebace660","executionInfo":{"status":"ok","timestamp":1710747361937,"user_tz":-330,"elapsed":29,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["train_size = 0.8\n","train_dataset = data.sample(frac=train_size,random_state=200)\n","test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(data.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n","testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (47571, 2)\n","TRAIN Dataset: (38057, 2)\n","TEST Dataset: (9514, 2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ptv5AT_iTb7W"},"source":["Let's have a look at the first training example:"]},{"cell_type":"code","metadata":{"id":"phmPylgAm8Xy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f1f98453-bd98-4bf1-f339-c1e3790420db","executionInfo":{"status":"ok","timestamp":1710747361937,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["training_set[0]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ids': tensor([  101, 23564, 21030,  2099,  4967,  2001,  9388,  1011,  6109,  2005,\n","          2634,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'targets': tensor([0, 3, 3, 3, 8, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0])}"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"VvU4nzL2W2Xo"},"source":["Let's verify that the input ids and corresponding targets are correct:"]},{"cell_type":"code","source":["training_set[0][\"ids\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHoufyakY18x","outputId":"d1ffe318-538d-4007-e622-1b47a6e4a5ca","executionInfo":{"status":"ok","timestamp":1710747361937,"user_tz":-330,"elapsed":17,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  101, 23564, 21030,  2099,  4967,  2001,  9388,  1011,  6109,  2005,\n","         2634,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"DWgnNJrYW2GP","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"65a55c68-b756-46b9-f215-2ac882d6a336","executionInfo":{"status":"ok","timestamp":1710747361939,"user_tz":-330,"elapsed":14,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["# print the first 30 tokens and corresponding labels\n","for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"][:30]), training_set[0][\"targets\"][:30]):\n","  print('{0:10}  {1}'.format(token, id2label[label.item()]))"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS]       O\n","za          B-per\n","##hee       B-per\n","##r         B-per\n","khan        I-per\n","was         O\n","mar         O\n","-           O\n","93          O\n","for         O\n","india       B-geo\n",".           O\n","[SEP]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ky68FcTgWnfN"},"source":["Now, let's define the corresponding PyTorch dataloaders:"]},{"cell_type":"code","metadata":{"id":"KIw793myWOmi","executionInfo":{"status":"ok","timestamp":1710747361939,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"73OzU7oXRxR8"},"source":["#### **Defining the model**"]},{"cell_type":"markdown","metadata":{"id":"T-iGhnhdLNdP"},"source":["Here we define the model, BertForTokenClassification, and load it with the pretrained weights of \"bert-base-uncased\". The only thing we need to additionally specify is the number of labels (as this will determine the architecture of the classification head).\n","\n","Note that only the base layers are initialized with the pretrained weights. The token classification head of top has just randomly initialized weights, which we will train, together with the pretrained weights, using our labelled dataset. This is also printed as a warning when you run the code cell below.\n","\n","Then, we move the model to the GPU."]},{"cell_type":"code","metadata":{"id":"cB9MR3KcWXUs","tags":[],"colab":{"base_uri":"https://localhost:8080/","height":815,"referenced_widgets":["491c376d88e443f5ae64f8dd17444242","469c61c781ab469383b446bacc9ac35d","c5ef40d523044ebda92b72f671f227b2","f7bec5cb1c28448e99b822c3c639b022","45901b63fbfe47239b403541d166a097","0008ee1275df41b8b4537de220482e6a","3a44ea90c28c45d69945de4b85053af5","3d8cfda319e84010b30e4a1752d716e1","fbde2bbb44ff4b0495b341521091900d","4711ad35dda8446aa8560ee053a04e77","cb66d19064dc4f6296005b387ffad960"]},"outputId":"311120fa-b870-469a-a022-b93a016619af","executionInfo":{"status":"ok","timestamp":1710747368417,"user_tz":-330,"elapsed":6489,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n","                                                   num_labels=len(id2label),\n","                                                   id2label=id2label,\n","                                                   label2id=label2id)\n","model.to(device)"],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"491c376d88e443f5ae64f8dd17444242"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"Pp7Yl4JyWhDj"},"source":["#### **Training the model**\n","\n","\n","Why? Because we are using cross entropy loss. The cross entropy loss is defined as -ln(probability score of the model for the correct class). In the beginning, the weights are random, so the probability distribution for all of the classes for a given token will be uniform, meaning that the probability for the correct class will be near 1/17. The loss for a given token will thus be -ln(1/17). As PyTorch's [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) (which is used by `BertForTokenClassification`) uses *mean reduction* by default, it will compute the mean loss for each of the tokens in the sequence (in other words, for all of the 512 tokens). The mean of 512 times -log(1/17) is, you guessed it, -log(1/17).  \n","\n","Let's verify this:\n","\n"]},{"cell_type":"code","metadata":{"id":"eqAN7YVIjKTr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8b5b6dc-e03f-4bdd-a511-bd5351a196b3","executionInfo":{"status":"ok","timestamp":1710747372517,"user_tz":-330,"elapsed":4127,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["ids = training_set[0][\"ids\"].unsqueeze(0)\n","mask = training_set[0][\"mask\"].unsqueeze(0)\n","targets = training_set[0][\"targets\"].unsqueeze(0)\n","ids = ids.to(device)\n","mask = mask.to(device)\n","targets = targets.to(device)\n","outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n","initial_loss = outputs[0]\n","initial_loss"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.5674, device='cuda:0', grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"yLdwsru9Mh7U"},"source":["This looks good. Let's also verify that the logits of the neural network have a shape of (batch_size, sequence_length, num_labels):"]},{"cell_type":"code","metadata":{"id":"X-z6YCpGnvfj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0d0c7a4-1989-4dbb-8825-994aa81723d5","executionInfo":{"status":"ok","timestamp":1710747372517,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["tr_logits = outputs[1]\n","tr_logits.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 128, 11])"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"kwDLXxOVOCvD"},"source":["Next, we define the optimizer. Here, we are just going to use Adam with a default learning rate. One can also decide to use more advanced ones such as AdamW (Adam with weight decay fix), which is [included](https://huggingface.co/transformers/main_classes/optimizer_schedules.html) in the Transformers repository, and a learning rate scheduler, but we are not going to do that here."]},{"cell_type":"code","metadata":{"id":"kznSQfGIWdU4","executionInfo":{"status":"ok","timestamp":1710747372517,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vZQ8JMF0NOe1"},"source":["Now let's define a regular PyTorch training function. It is partly based on [a really good repository about multilingual NER](https://github.com/chambliss/Multilingual_NER/blob/master/python/utils/main_utils.py#L344)."]},{"cell_type":"code","metadata":{"id":"GLFivpkwW1HY","executionInfo":{"status":"ok","timestamp":1710747372518,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["# Defining the training function on the 80% of the dataset for tuning the bert model\n","def train(epoch):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    # put model in training mode\n","    model.train()\n","\n","    for idx, batch in enumerate(training_loader):\n","\n","        ids = batch['ids'].to(device, dtype = torch.long)\n","        mask = batch['mask'].to(device, dtype = torch.long)\n","        targets = batch['targets'].to(device, dtype = torch.long)\n","\n","        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n","        loss, tr_logits = outputs.loss, outputs.logits\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += targets.size(0)\n","\n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","\n","        # compute training accuracy\n","        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n","        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n","        targets = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","\n","        tr_preds.extend(predictions)\n","        tr_labels.extend(targets)\n","\n","        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","\n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","\n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k2dsCyP7dcF3"},"source":["And let's train the model!"]},{"cell_type":"code","metadata":{"id":"y07Ybw8rZeZ7","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"59ac086f-7355-416c-f780-5ac904958ca7","executionInfo":{"status":"ok","timestamp":1710748532873,"user_tz":-330,"elapsed":1160360,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["for epoch in range(EPOCHS):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    train(epoch)"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 2.494814872741699\n","Training loss per 100 training steps: 0.42212079716200873\n","Training loss per 100 training steps: 0.2782439620451844\n","Training loss per 100 training steps: 0.21800724136027386\n","Training loss per 100 training steps: 0.18166521831678037\n","Training loss per 100 training steps: 0.15837714216948864\n","Training loss per 100 training steps: 0.14222591476105836\n","Training loss per 100 training steps: 0.12976865641329008\n","Training loss per 100 training steps: 0.11923070081780558\n","Training loss per 100 training steps: 0.11112766696830652\n","Training loss per 100 training steps: 0.1047282716469629\n","Training loss per 100 training steps: 0.09919196786210922\n","Training loss per 100 training steps: 0.09432190299157416\n","Training loss per 100 training steps: 0.09057759374292777\n","Training loss per 100 training steps: 0.0871767546716668\n","Training loss per 100 training steps: 0.08415880793135372\n","Training loss per 100 training steps: 0.08125348481364772\n","Training loss per 100 training steps: 0.07883632931171718\n","Training loss per 100 training steps: 0.0767039132721025\n","Training loss per 100 training steps: 0.0745075176885672\n","Training loss per 100 training steps: 0.07275931385689244\n","Training loss per 100 training steps: 0.07103946793486215\n","Training loss per 100 training steps: 0.06953833322537921\n","Training loss per 100 training steps: 0.06810274263576761\n","Training loss per 100 training steps: 0.06664003893947916\n","Training loss per 100 training steps: 0.06537213168156872\n","Training loss per 100 training steps: 0.06420077671239963\n","Training loss per 100 training steps: 0.06316340146779391\n","Training loss per 100 training steps: 0.062228462651320586\n","Training loss per 100 training steps: 0.061189369887717275\n","Training loss per 100 training steps: 0.060308603603788986\n","Training loss per 100 training steps: 0.059385733919613715\n","Training loss per 100 training steps: 0.05860907251908659\n","Training loss per 100 training steps: 0.05778430471715473\n","Training loss per 100 training steps: 0.057096689409588404\n","Training loss per 100 training steps: 0.05638123131886838\n","Training loss per 100 training steps: 0.05566198853826615\n","Training loss per 100 training steps: 0.05500996645268667\n","Training loss per 100 training steps: 0.0545285707957249\n","Training loss per 100 training steps: 0.05402179314972216\n","Training loss per 100 training steps: 0.05343766909710268\n","Training loss per 100 training steps: 0.05295564008229059\n","Training loss per 100 training steps: 0.05243116825637728\n","Training loss per 100 training steps: 0.05186419905203894\n","Training loss per 100 training steps: 0.05138558389584235\n","Training loss per 100 training steps: 0.05087332197949338\n","Training loss per 100 training steps: 0.05048652904156899\n","Training loss per 100 training steps: 0.05017053029589891\n","Training loss per 100 training steps: 0.049735193969363725\n","Training loss per 100 training steps: 0.04934558468605066\n","Training loss per 100 training steps: 0.04898624297492061\n","Training loss per 100 training steps: 0.04863091992382566\n","Training loss per 100 training steps: 0.0482792989495675\n","Training loss per 100 training steps: 0.048003369524257655\n","Training loss per 100 training steps: 0.047662225987215937\n","Training loss per 100 training steps: 0.04730548159945793\n","Training loss per 100 training steps: 0.047023177816762185\n","Training loss per 100 training steps: 0.0467224601686257\n","Training loss per 100 training steps: 0.04640247548098803\n","Training loss per 100 training steps: 0.04610993673895444\n","Training loss per 100 training steps: 0.045830863011718306\n","Training loss per 100 training steps: 0.04554502545625665\n","Training loss per 100 training steps: 0.04526688224615968\n","Training loss per 100 training steps: 0.045035194296490624\n","Training loss per 100 training steps: 0.04477225998649701\n","Training loss per 100 training steps: 0.04450509464608182\n","Training loss per 100 training steps: 0.04427532546250851\n","Training loss per 100 training steps: 0.04406939620223553\n","Training loss per 100 training steps: 0.04387171328952714\n","Training loss per 100 training steps: 0.0436635453731488\n","Training loss per 100 training steps: 0.043410604410380985\n","Training loss per 100 training steps: 0.04319882035694338\n","Training loss per 100 training steps: 0.04297223892171865\n","Training loss per 100 training steps: 0.04278100887838877\n","Training loss per 100 training steps: 0.04257268639117772\n","Training loss per 100 training steps: 0.042321766065607135\n","Training loss per 100 training steps: 0.04209000089213245\n","Training loss per 100 training steps: 0.04190989997278706\n","Training loss per 100 training steps: 0.04175801220408884\n","Training loss per 100 training steps: 0.041599005953570384\n","Training loss per 100 training steps: 0.041433771293402095\n","Training loss per 100 training steps: 0.04125464689836339\n","Training loss per 100 training steps: 0.04105925898772746\n","Training loss per 100 training steps: 0.04091487502921049\n","Training loss per 100 training steps: 0.040787890925692356\n","Training loss per 100 training steps: 0.04064406932194282\n","Training loss per 100 training steps: 0.04050990393652785\n","Training loss per 100 training steps: 0.04038285630637962\n","Training loss per 100 training steps: 0.040272218817914165\n","Training loss per 100 training steps: 0.04012086925983704\n","Training loss per 100 training steps: 0.03998724518593567\n","Training loss per 100 training steps: 0.03984955187878114\n","Training loss per 100 training steps: 0.03973009442054322\n","Training loss per 100 training steps: 0.039599189062973376\n","Training loss per 100 training steps: 0.03945587840036545\n","Training loss per 100 training steps: 0.039307001300659394\n","Training loss epoch: 0.03928875381149818\n","Training accuracy epoch: 0.9490969367721945\n"]}]},{"cell_type":"markdown","metadata":{"id":"r4jcSOJr680a"},"source":["#### **Evaluating the model**"]},{"cell_type":"markdown","metadata":{"id":"rYUTuOEUdfFJ"},"source":["Now that we've trained our model, we can evaluate its performance on the held-out test set (which is 20% of the data). Note that here, no gradient updates are performed, the model just outputs its logits."]},{"cell_type":"code","metadata":{"id":"RIVVfFHi7Aw7","executionInfo":{"status":"ok","timestamp":1710748532873,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["def valid(model, testing_loader):\n","    # put model in evaluation mode\n","    model.eval()\n","\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","\n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","\n","            ids = batch['ids'].to(device, dtype = torch.long)\n","            mask = batch['mask'].to(device, dtype = torch.long)\n","            targets = batch['targets'].to(device, dtype = torch.long)\n","\n","            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n","            loss, eval_logits = outputs.loss, outputs.logits\n","\n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += targets.size(0)\n","\n","            if idx % 100==0:\n","                loss_step = eval_loss/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n","\n","            # compute evaluation accuracy\n","            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n","            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n","            targets = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","\n","            eval_labels.extend(targets)\n","            eval_preds.extend(predictions)\n","\n","            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    #print(eval_labels)\n","    #print(eval_preds)\n","\n","    labels = [id2label[id.item()] for id in eval_labels]\n","    predictions = [id2label[id.item()] for id in eval_preds]\n","\n","    #print(labels)\n","    #print(predictions)\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJaONluRdq-e"},"source":["As we can see below, performance is quite good! Accuracy on the test test is > 93%."]},{"cell_type":"code","metadata":{"id":"2BrxRjvxApY8","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1440b3b7-04e0-43e4-e498-6c74888aaf54","executionInfo":{"status":"ok","timestamp":1710748635237,"user_tz":-330,"elapsed":102368,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["labels, predictions = valid(model, testing_loader)"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation loss per 100 evaluation steps: 0.022168276831507683\n","Validation loss per 100 evaluation steps: 0.03498757758672294\n","Validation loss per 100 evaluation steps: 0.030928497644898884\n","Validation loss per 100 evaluation steps: 0.030241176809396586\n","Validation loss per 100 evaluation steps: 0.02987054357698325\n","Validation loss per 100 evaluation steps: 0.029821687755220826\n","Validation loss per 100 evaluation steps: 0.02903868133327521\n","Validation loss per 100 evaluation steps: 0.02820855093211377\n","Validation loss per 100 evaluation steps: 0.02812808732794545\n","Validation loss per 100 evaluation steps: 0.028193700280074483\n","Validation loss per 100 evaluation steps: 0.027667085060280035\n","Validation loss per 100 evaluation steps: 0.027641974038588896\n","Validation loss per 100 evaluation steps: 0.027533799860939356\n","Validation loss per 100 evaluation steps: 0.02742076008859919\n","Validation loss per 100 evaluation steps: 0.026989560352160904\n","Validation loss per 100 evaluation steps: 0.0269308097901923\n","Validation loss per 100 evaluation steps: 0.02721821597874853\n","Validation loss per 100 evaluation steps: 0.027083968238441294\n","Validation loss per 100 evaluation steps: 0.02699454135537017\n","Validation loss per 100 evaluation steps: 0.027029756602044663\n","Validation loss per 100 evaluation steps: 0.02706810730496559\n","Validation loss per 100 evaluation steps: 0.026986118528446516\n","Validation loss per 100 evaluation steps: 0.02702436382028792\n","Validation loss per 100 evaluation steps: 0.02699980442609828\n","Validation loss per 100 evaluation steps: 0.02701486486278576\n","Validation loss per 100 evaluation steps: 0.027131696379096647\n","Validation loss per 100 evaluation steps: 0.027102881613483475\n","Validation loss per 100 evaluation steps: 0.02726080951593847\n","Validation loss per 100 evaluation steps: 0.027289762244853376\n","Validation loss per 100 evaluation steps: 0.027239581483660808\n","Validation loss per 100 evaluation steps: 0.02730528963602695\n","Validation loss per 100 evaluation steps: 0.02727229449296707\n","Validation loss per 100 evaluation steps: 0.027404642490073208\n","Validation loss per 100 evaluation steps: 0.027535191896225435\n","Validation loss per 100 evaluation steps: 0.027563819278832\n","Validation loss per 100 evaluation steps: 0.02756358353434418\n","Validation loss per 100 evaluation steps: 0.027583469311362973\n","Validation loss per 100 evaluation steps: 0.02748616966877852\n","Validation loss per 100 evaluation steps: 0.027407938459795545\n","Validation loss per 100 evaluation steps: 0.027401350433663357\n","Validation loss per 100 evaluation steps: 0.027346411150065832\n","Validation loss per 100 evaluation steps: 0.027391643937652532\n","Validation loss per 100 evaluation steps: 0.02726263277389022\n","Validation loss per 100 evaluation steps: 0.027278322835246848\n","Validation loss per 100 evaluation steps: 0.027255955158413264\n","Validation loss per 100 evaluation steps: 0.027260141150309294\n","Validation loss per 100 evaluation steps: 0.027283468533687315\n","Validation loss per 100 evaluation steps: 0.02723138881789098\n","Validation Loss: 0.027229536512294584\n","Validation Accuracy: 0.9602956126975882\n"]}]},{"cell_type":"markdown","metadata":{"id":"SAznLDwx_U2X"},"source":["However, the accuracy metric is misleading, as a lot of labels are \"outside\" (O), even after omitting predictions on the [PAD] tokens. What is important is looking at the precision, recall and f1-score of the individual tags. For this, we use the seqeval Python library:"]},{"cell_type":"code","metadata":{"id":"0jDNXrjr-6BW","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"550efcc2-061d-437f-e12c-00fa456b20da","executionInfo":{"status":"ok","timestamp":1710748640312,"user_tz":-330,"elapsed":5099,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["from seqeval.metrics import classification_report\n","\n","print(classification_report([labels], [predictions]))"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         geo       0.76      0.92      0.84     11232\n","         gpe       0.94      0.91      0.92      3293\n","         org       0.71      0.59      0.65      6531\n","         per       0.77      0.78      0.77      5196\n","         tim       0.78      0.85      0.81      4360\n","\n","   micro avg       0.77      0.82      0.79     30612\n","   macro avg       0.79      0.81      0.80     30612\n","weighted avg       0.77      0.82      0.79     30612\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"4Gz-wHAw3xMk"},"source":["#### **Inference**\n","\n","The fun part is when we can quickly test the model on new, unseen sentences.\n","Here, we use the prediction of the **first word piece of every word**. Note that the function we used to train our model (`tokenze_and_preserve_labels`) propagated the label to all subsequent word pieces (so you could for example also perform a majority vote on the predicted labels of all word pieces of a word).\n","\n","*In other words, the code below does not take into account when predictions of different word pieces that belong to the same word do not match.*"]},{"cell_type":"code","metadata":{"id":"zPDla1mmZiax","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c38adb1-7f47-47e6-fe61-ca36d0bd76bf","executionInfo":{"status":"ok","timestamp":1710748640312,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"source":["sentence = \"India has a capital called Mumbai. On wednesday, the president will give a presentation\"\n","\n","inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n","\n","# move to gpu\n","ids = inputs[\"input_ids\"].to(device)\n","mask = inputs[\"attention_mask\"].to(device)\n","# forward pass\n","outputs = model(ids, mask)\n","logits = outputs[0]\n","\n","active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n","\n","tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n","token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n","wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n","\n","word_level_predictions = []\n","for pair in wp_preds:\n","  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n","    # skip prediction\n","    continue\n","  else:\n","    word_level_predictions.append(pair[1])\n","\n","# we join tokens, if they are not special ones\n","str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n","print(str_rep)\n","print(word_level_predictions)"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["india has a capital called mumbai . on wednesday , the president will give a presentation\n","['B-geo', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"]}]},{"cell_type":"markdown","source":["Note that there's another way to easily perform quick inference with a trained model: the [pipeline API](https://huggingface.co/docs/transformers/main_classes/pipelines). The pipeline API abstracts away all the complexity for you (basically performing what we did above). Here, we'll use the [TokenClassificationPipeline](https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/pipelines#transformers.TokenClassificationPipeline) since that's the task we're doing, and we provide a model and tokenizer."],"metadata":{"id":"bDIqKc-9cXBl"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","pipe = pipeline(task=\"token-classification\", model=model.to(\"cpu\"), tokenizer=tokenizer, aggregation_strategy=\"simple\")\n","pipe(\"My name is Niels and New York is a city\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5KB5TKRcdRT","outputId":"0f539622-9236-4423-8fb4-741a1f99ae47","executionInfo":{"status":"ok","timestamp":1710748644127,"user_tz":-330,"elapsed":3832,"user":{"displayName":"Sai Chandra Reddy","userId":"00259055063741786088"}}},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'entity_group': 'per',\n","  'score': 0.5380146,\n","  'word': 'ni',\n","  'start': None,\n","  'end': None},\n"," {'entity_group': 'per',\n","  'score': 0.54281044,\n","  'word': '##els',\n","  'start': None,\n","  'end': None},\n"," {'entity_group': 'geo',\n","  'score': 0.9756768,\n","  'word': 'new york',\n","  'start': None,\n","  'end': None}]"]},"metadata":{},"execution_count":37}]}]}